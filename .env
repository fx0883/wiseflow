export LLM_API_KEY="ollama"
export LLM_API_BASE="http://192.168.31.32:11434/v1" ##for local model services or calling non-OpenAI services with openai_wrapper
##strongly recommended to use the following model provided by siliconflow (consider both effect and price)
export GET_INFO_MODEL="qwen2:7b-instruct" ##
export REWRITE_MODEL="qwen2:7b-instruct"
export HTML_PARSE_MODEL="qwen2:7b-instruct"
export PROJECT_DIR="work"
export PB_API_AUTH="test@example.com|1234567890"
# export PB_API_BASE="192.168.31.140:8090" ##only use if your pb not run on 127.0.0.1:8090
export WS_LOG="verbose" ##for detail log info. If not need, just delete this item.
export VOLC_KEY="1|1"